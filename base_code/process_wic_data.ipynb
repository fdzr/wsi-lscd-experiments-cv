{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"wic6\"\n",
    "wic_path = f\"../input/wic/dwug_es/scores/models/{model}/train\"\n",
    "wic_path_input = \"../input/wic\"\n",
    "path_to_gold_data_dwug_es = \"../test_data_es.csv\"\n",
    "path_to_annotated_data_dwug_es = \"../dwug_es/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = next(Path(wic_path_input).glob(\"*.data\"))\n",
    "data_input = pd.read_json(p)\n",
    "display(data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data_input[\"sentence1\"] == data_input[\"sentence2\"]\n",
    "data_input = data_input[~mask]\n",
    "print(data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data_input.duplicated(subset=[\"sentence1\", \"sentence2\"], keep=False)\n",
    "data_input = data_input[~mask]\n",
    "print(data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_be_concatenated = [pd.read_json(data) for data in Path(wic_path).rglob(\"*.scores\")]\n",
    "data_scores = pd.concat(data_to_be_concatenated, ignore_index=True)\n",
    "display(data_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data_dwug_es = pd.read_csv(path_to_gold_data_dwug_es, sep=\"\\t\")\n",
    "display(gold_data_dwug_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_words_dwug_es = gold_data_dwug_es[\"word\"].unique().tolist()\n",
    "target_words_dwug_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_expanded = data_input.merge(data_scores, on=\"id\", how=\"inner\")\n",
    "data_input_expanded.drop(columns=[\"pos\"], inplace=True)\n",
    "display(data_input_expanded)\n",
    "\n",
    "mask = data_input_expanded[\"lemma\"].isin(target_words_dwug_es)\n",
    "data_input_expanded_filtered = data_input_expanded[mask]\n",
    "data_input_expanded_filtered = data_input_expanded_filtered.drop(columns=[\"start1\", \"end1\", \"start2\", \"end2\"])\n",
    "display(data_input_expanded_filtered)\n",
    "print(len(data_input_expanded_filtered[\"lemma\"].unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data_input_expanded_filtered[\"sentence1\"] == data_input_expanded_filtered[\"sentence2\"]\n",
    "display(data_input_expanded_filtered[mask].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data_to_be_concatenated_dwug_es = [\n",
    "    pd.read_csv(p, sep=\"\\t\")\n",
    "    for p in Path(path_to_annotated_data_dwug_es).rglob(\"*uses.csv\")\n",
    "]\n",
    "annotated_data_dwug_es = pd.concat(\n",
    "    annotated_data_to_be_concatenated_dwug_es, ignore_index=True\n",
    ")\n",
    "display(annotated_data_dwug_es)\n",
    "\n",
    "mask = annotated_data_dwug_es[\"lemma\"].isin(target_words_dwug_es)\n",
    "annotated_data_dwug_es_filtered = annotated_data_dwug_es[mask]\n",
    "annotated_data_dwug_es_filtered = annotated_data_dwug_es_filtered[\n",
    "    [\"lemma\", \"grouping\", \"identifier\", \"context\"]\n",
    "]\n",
    "# display(annotated_data_dwug_es_filtered)\n",
    "annotated_data_dwug_es_filtered = annotated_data_dwug_es_filtered[\n",
    "    ~annotated_data_dwug_es_filtered.duplicated(subset=\"context\", keep=False)\n",
    "]\n",
    "display(annotated_data_dwug_es_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1 = data_input_expanded_filtered.merge(\n",
    "    annotated_data_dwug_es_filtered,\n",
    "    left_on=[\"lemma\", \"sentence1\"],\n",
    "    right_on=[\"lemma\", \"context\"],\n",
    "    how=\"inner\",\n",
    ").rename(columns={\"identifier\": \"identifier1\"})\n",
    "\n",
    "\n",
    "merged2 = merged1.merge(\n",
    "    annotated_data_dwug_es_filtered,\n",
    "    left_on=[\"lemma\", \"sentence2\"],\n",
    "    right_on=[\"lemma\", \"context\"],\n",
    "    how=\"inner\",\n",
    ").rename(columns={\"identifier\": \"identifier2\"})\n",
    "print(merged2.shape)\n",
    "\n",
    "result = merged2[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"lemma\",\n",
    "        \"sentence1\",\n",
    "        \"sentence2\",\n",
    "        \"score\",\n",
    "        \"identifier1\",\n",
    "        \"identifier2\",\n",
    "        \"grouping_x\",\n",
    "    ]\n",
    "]\n",
    "result[\"score\"] = result[\"score\"].apply(lambda x: sum(float(e) for e in x) / len(x))\n",
    "result.rename(columns={\"grouping_x\": \"grouping\", \"lemma\": \"word\"}, inplace=True)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = result[result.isna().any(axis=1)]  # or df[df.isnull().any(axis=1)]\n",
    "\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(f\"{model}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tw in target_words_dwug_es:\n",
    "    mask = result[\"word\"] == tw\n",
    "    df = result[mask]\n",
    "\n",
    "    print(tw, df.shape[0])\n",
    "    assert df.shape[0] <= 780\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame({\"sentence1\": [\"bla bla A\", \"bla bla B\", \"bla bla C\"], \"sentence2\": [\"bla bla C\", \"bla bla A\", \"bla bla B\"]})\n",
    "B = pd.DataFrame({\"context\": [\"bla bla B\", \"bla bla C\", \"bla bla A\"], \"identifier\": [\"b1\", \"c1\", \"a1\"]})\n",
    "display(A)\n",
    "print()\n",
    "display(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1 = A.merge(B, left_on=\"sentence1\", right_on=\"context\", how=\"left\")\n",
    "display(merged1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
